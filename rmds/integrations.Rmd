---
title: "Evaluating integrations"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "/n/janson_lab/lab/sma/sparsedossa_update/")
knitr::opts_chunk$set(echo=FALSE)
library(magrittr)
library(ggplot2)
```

```{r register}
# batchtools::makeRegistry(file.dir = "r_batchtools_reg/integrations/", 
#                          package = "magrittr")
batchtools::loadRegistry(file.dir = "r_batchtools_reg/integrations/", 
                         writeable = TRUE)
batchtools::clearRegistry()

# Grid parameters
ncpus <- 1
partition <- "janson_cascade"
walltime <- 600
```

```{r load data}
smar::sourceDir("SparseDOSSA2/R/")
dir_output <- "results/integrations/"
dir.create(dir_output)

load("results/Simulation_smaller/tb_job.RData")
i_tb_job <- tb_job %>% 
  dplyr::filter(dataset == "stool") %>% 
  dplyr::slice(1)
params_subset <- sapply(
  i_tb_job$params[[1]]$mu,
  function(i_mu) {
    i_mu %in% i_tb_job$params_sim[[1]]$mu
  }
)

params <- i_tb_job$params_sim[[1]]
x_samples <- i_tb_job$x_samples[[1]][1:5, ]
a_samples <- i_tb_job$a_samples[[1]][1:5, ]

# compare dloga, fixing as
load("results/Stool_vaginal/tb_job.RData")
tb_params <- tb_job %>% 
  dplyr::filter(penalize_method == "huge",
                dataset == "stool",
                lambdas > 1e-2)
l_params <- tb_params$i_job %>% 
  purrr::map(~ {
    load(paste0("results/Stool_vaginal/fit_", .x, ".RData"))
    i_params <- fit_EM$l_fits_full[[1]]$fit
    i_params$pi0 <- params$pi0
    i_params$mu <- params$mu
    i_params$sigma <- params$sigma
    i_params$Sigma <- i_params$Sigma[params_subset, 
                                     params_subset]
    i_params$Omega <- solve(i_params$Sigma)
    i_params
  })

tb_job <- rbind(
  tibble::tibble(method = "hcubature",
                 max_eval = c(15, 45, 75, 135)),
  tibble::tibble(method = "pcubature",
                 max_eval = c(9, 17, 33, 65)),
  tibble::tibble(method = "cubspline",
                 max_eval = c(17, 33, 65, 129))
) %>% 
  tidyr::expand_grid(
    limit_tol = c(1e-2, 1e-3, 1e-4, 1e-5),
    i_sample = seq_len(nrow(x_samples)),
    i_param = seq_along(l_params)
  ) %>% 
  dplyr::mutate(i_job = seq_len(dplyr::n()))
save(tb_job, file = paste0(dir_output, "tb_job.RData"))
```

```{r one job}
one_job <- function(i_job) {
  i_tb_job <- tb_job[i_job, ]
  i_params <- l_params[[i_tb_job$i_param]]
  # get limits
  limits <- get_intLimits2(
    x = x_samples[i_tb_job$i_sample, ],
    pi0 = i_params$pi0, mu = i_params$mu, sigma = i_params$sigma,
    Sigma = i_params$Sigma, Omega = i_params$Omega,
    limit_tol = i_tb_job$limit_tol)
  fit_integrate <- 
    integrate2(
      f = vintegrand_dx,
      lower = limits[1], upper = limits[2], 
      rel_tol = 1e-5, abs_tol = 0, 
      method = i_tb_job$method, 
      max_eval = i_tb_job$max_eval, 
      offset = TRUE,
      x = x_samples[i_tb_job$i_sample, ],
      pi0 = i_params$pi0, mu = i_params$mu, sigma = i_params$sigma,
      Sigma = i_params$Sigma, Omega = i_params$Omega)
  save(fit_integrate, file = paste0(dir_output, "fit_", i_job, ".RData"))
}
```

```{r submit jobs}
tb_ids <- batchtools::batchMap(one_job, 
                               i_job = tb_job$i_job)
batchtools::batchExport(mget(ls()))
batchtools::submitJobs(resources =  list(ncpus = ncpus, 
                                         partition = partition,
                                         walltime = walltime))
```