---
title: "New model for X"
author: "Siyuan Ma"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = "../")
library(magrittr)
library(ggplot2)
```

## Agenda

* New model fitted results
  
* Model
  
* Identifiability
  
* EM fitting

* MCMC sampling

* $a$ to $g$ mapping, Jacobian

* Logistics - extending my appointment?

* ZIPFA

```{r load data, include=FALSE}
load("../data/physeqs/genera.RData")
physeq <- physeq_genera %>% 
  phyloseq::subset_samples(dataset_name == "MucosalIBD") %>% 
  smar::prune_taxaSamples(flist_taxa = genefilter::kOverA(k = 5, A = 1))
mat_X_count <- t(smar::otu_table2(physeq))
colnames(mat_X_count) <- CRTmicrobiome:::simplify_feature(colnames(mat_X_count))
mat_X <- t(apply(mat_X_count, 1, function(x) x / sum(x)))
```

```{r sample from estimated distributions, include=FALSE}
load("../results/EM_diagnostics/mcmc.RData")
params <- fit_EM_mcmc$ll_params[[20]]
samples_A <- SparseDOSSA2:::rcopulasso(n = 10000,
                                       mean = params$mu,
                                       sd = params$sigma,
                                       pi0 = params$pi0,
                                       sigma = solve(params$Omega))
colnames(samples_A) <- colnames(mat_X)
samples_X <- t(apply(samples_A, 1, function(x) x / sum(x)))
```

## New model seems to approximate marginals and correlations

* [Marginals](https://www.dropbox.com/s/q18lbadxlez6umz/marginals.pdf?dl=0)

* Correlations

```{r plotting, echo=FALSE}
# df_original <- t(mat_X) %>% 
#   CRTmicrobiome:::longify_abd() %>% 
#   dplyr::mutate(data = "original")
# df_samples <- t(samples_X) %>% 
#   CRTmicrobiome:::longify_abd() %>% 
#   dplyr::mutate(data = "copulasso")
# df_p <- rbind(df_original,
#               df_samples) %>%
#   dplyr::filter(abd > 0) %>% 
#   dplyr::mutate(
#     data = factor(data, levels = c("original", "copulasso")),
#     log_abd = log10(abd)) %>%
#   dplyr::group_by(feature) %>%
#   dplyr::summarise(
#     l_p = list(
#       data.frame(log_abd = log_abd,
#                  data = data) %>%
#         ggplot(aes(x = log_abd)) +
#         geom_histogram(bins = 50) +
#         facet_grid(data~., scales = "free_y") +
#         ggtitle(feature[1])
#     ))
# pdf("../results/EM_diagnostics/marginals.pdf", width = 4, height = 8)
# for(i in seq_along(df_p$l_p)) {
#   print(df_p$l_p[[i]])
# }
# dev.off()
cor_original <- cor(mat_X, method = "spearman")
cor_sample <- cor(samples_X, method = "spearman")
CRTmicrobiome:::plot_cors(cor_original, cor_sample, 
                          labels = c("original", "copulasso")) +
  coord_fixed()
```

## The model

\begin{align}
    f_{a}(a) 
      &= \prod_j f_{a_j}(a_j) \times \frac{f_{a}(a)}{\prod_j f_{a_j}(a_j)} \\
      &= \prod_j f_{a_j}(a_j) \times \frac{f_{g}(g)}{\prod_j f_{g_j}(g_j)} \\
      &= \prod_j f_{a_j}(a_j | \mu_j, \sigma_j, \pi_{0j}) \times \frac{f_{g}(g | \Omega)}{\prod_j f_{g_j}(g_j)}
\end{align}

$f_{a_j}(a_j | \mu_j, \sigma_j, \pi_{0j}) \sim$ zero-inflated log normal. 
$f_g(g | \Omega) \sim$ MVN. $f_{g_j}(g_j) \sim$ standard normal.

Let $a^s = \sum_j a_j$. $x_j = a_j / a^s$,

\begin{align}
f_x(x) = \int f_a(a) (a^s)^{p - 1} da^s
\end{align}

## Identifiability

Not all parameters for $f_a(a)$ are identifiable from $f_x(x)$ - constraints 
needed for maximizing likelihood!

* $\Omega$ not identifiable. 
  
  * Example: let $\log a \sim$ MVN with unit marginal variance (i.e., 
    $\pi_{0j} = 0, \sigma_j = 1$). Then integrating over $a$ gives 
    $\Omega - \frac{\Omega \mathbf{1}_p\mathbf{1}_p^\prime \Omega}{\mathbf{1}_p^\prime \Omega \mathbf{1}_p}$ in the likelihood for $\log x$. $\Omega + c$
    map to the same value (Fang et al., 2017)!
    
  * Solution: $L_1$ penalization.

* Given $\Omega$, $\sigma_j$ is identifiable.
  
  * Intuition: only the log-MVN case ($\pi_{0j} = 0$). 
    $F diag (\sigma_1, \dots, \sigma_p) = F diag (\sigma_1^*, \dots, \sigma_p^*)$
    gives that $\sigma_1 = \sigma_1^*, \dots, \sigma_p = \sigma_p^*$!

* $\mu_j$ not identifiable. 
  
  * Example: for $a \sim f_a$, $c \cdot a$ yields the same 
    marginal on $x$ for constant $c$.
    
  * Solution: 
    
    * Note that $\mu_j = E [\log a_j | a_j > 0] = E [\log x_j | x_j > 0] + E [\log a^s | a_j > 0]$.
    
    * If further willing to assume $E [\log a^s | a_j > 0] = E[\log a^s]$, then
      have $\mu = (E [\log x_1 | x_1 > 0], \dots, E [\log x_p | x_p > 0]) + E[\log a^s]$
      
    * Since $\mu$ can be shifted by a constant and still yield the same marginals
      for $x$, can just estiamte $\mu$ as $(E [\log x_1 | x_1 > 0], \dots, E [\log x_p | x_p > 0])$

* $\pi_{0j}$ are identifiable ($a_j = 0 \Leftrightarrow x_j = 0$).

## EM fitting

* Identifiability of parameters leads to a penalized likelihood as objective 
  function. The minimization probelm is:
  
  \begin{align}
    -\log f_x(x | \hat{\mu}, \hat{\pi}_0, \sigma, \Omega) + \lambda ||\Omega||_1
  \end{align}

  where $\hat{\mu}, \hat{\pi}_0$ are directly estimated from $x$. For optimizing
  $\sigma$ and $\Omega$, we adopt a EM procedure
  
  * E-step: take expectation of $a^s$, given $x, \sigma^{(i)}, \Omega^{(i)}$
  
  * M-step: plug in $E [a^s | x]$, minimize objective function.
  
* The E-step can either be achieved via MCMC or numerical integration!

## MCMC sampler

With the new model, the sampler becomes 
$x_j^{(r)}|\frac{x_{-j}}{||x_{-j}||_1} \rightarrow a^{(r+1)}|x_j^{(r)}, \frac{x_{-j}}{||x_{-j}||_1} \rightarrow x^{(r+1)}|a^{(r+1)}, \frac{x_{-j}}{||x_{-j}||_1}$


## $a$ to $g$ mapping, Jacobian
  
* $a$ to $g$ mapping
  
  * With normal copula, by definition, $g_j = \Phi^{-1}(F_{a_j}(a_j))$
  
  * When $a_j$ has 0 discrete component, [two choices](https://arxiv.org/abs/1612.06968):
    
    * $F_{a_j}(0) = \pi_0 / 2$ (average rank)
    
    * Assume $g_j = \Phi^{-1}(u)$, where $u \sim U(0, \pi_{0j})$, given $a_j = 0$
      (breaking ties by randomization)
      
      * Need to marginalize over $u$s $\rightarrow$ either calculation of 
        $f(g_s | g_v \leq c)$, or Monte Carlo.
    
* The Jacobian $(a^s)^{p - 1}$ in $f_x(x) = \int f_a(a) (a^s)^{p - 1} da^s$ is 
  not correct.
  
  * Chain rule is not valid for when $x_j = 0$ (discrete component)
  
  * Write likelihood instead as $f_x(x) = f_x(x_{o^c} | x_o) \times f_x(x_o)$,
    where $o = \{j: x_j = 0\}$. 
    
  * Jacobian only wrt $x_{o^c}$

